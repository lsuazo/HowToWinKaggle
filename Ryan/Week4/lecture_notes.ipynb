{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning\n",
    "\n",
    "Cannot tune all parameters\n",
    "- There is often documentation providing recommendations on which params to tune first.\n",
    "- Can also just look at open source code (github, kaggle kernals) to see what choices are made\n",
    "\n",
    "Libraries for hyperparameter tuning\n",
    "1. hyperopt\n",
    "2. scikit-optimize\n",
    "3. spearmint\n",
    "4. GPyOpt\n",
    "5. RoBO\n",
    "5. SMAC3\n",
    "\n",
    "lecturer experience: performance of these libraries is similar\n",
    "\n",
    "My thoughts: The boundaries of the search space are chosen manually.  The first thing that should be done is to make sure that as one moves away from the boundary, the model score improves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees\n",
    "\n",
    "ref https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "* Hyperparameters\n",
    "    1. max-depth | max_depth\n",
    "        - good starting number i ~7\n",
    "        - if model score keeps improving with increasingtree depth, it suggests that there are important interactions between featrues; may benefit from feature engineeering\n",
    "    2. subsample| bagging_fraction: fraction of objects to use when fitting a tree\n",
    "        - fraction os samples to use at each split\n",
    "    3. colsample_bytree, colsample_bylevel | feature_fraction\n",
    "        - fraction of features o use at each split\n",
    "    4. min_child_weightt, lambda, alpha | min_data_in_leaf, lambda_l1, lambda_l2\n",
    "        - one of the most important parameters to tune\n",
    "        - optimal value for `min_child_weight` varies from 0 to 300+\n",
    "    5. `eta`, `num_weight`| `learning_rate`, `num_iterations`\n",
    "        - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models\n",
    "\n",
    "Lots of libraries out there\n",
    "* Keras: simplest, recommended\n",
    "* PyTorch: favored by research community, recommended\n",
    "* TensorFlow: Used extensively in production\n",
    "* fastai (not mentioned, perhaps considered part of PyTorch)\n",
    "\n",
    "Only consider *dense* networks (fully connected layers)\n",
    "\n",
    "1. Number of neurons per layer\n",
    "2. Number of layers\n",
    "    - can lead to optimization problems, can fail to converge\n",
    "3. Optimizer\n",
    "4. batch size\n",
    "    -larger --> prone to overfittiing\n",
    "    -start with 32 or 64 (higher leads to overfitting)\n",
    "5. Learning rate\n",
    "    - proper rate depends on problem, choice of other params\n",
    "    - too small, will take forever\n",
    "    -too large: will fail to converge\n",
    "    -tip: start with \"huge\" learning rate (say 0.1), then decrease it.\n",
    "    -If you increase batch size by alpha, can increase learning rate by same factor (this is a rule of thumb)\n",
    "6. Regularization\n",
    "    -l1, l2\n",
    "    -dropout/dropconnect\n",
    "        -dropout helps model find features that really matter\n",
    "        -tip: use dropout in layer right after data layer for this reason\n",
    "    -\n",
    "    \n",
    "    \n",
    "Recommendation: start simple (e.g. 1-2 layers, 64 neurons per layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing tips on hyperparameter tuning:\n",
    "1. be patient: GBDT and NNs can take a long time\n",
    "2. average over neighborhood of optimum\n",
    "    -e.g. if `max_depth` = 5 is found to be optimal, average over 4, 5, 6\n",
    "    -also average over `random_seed`\n",
    "        -Why does this help?  Your data has randomness that is inevitably incorporated in model.  Random seed has this same attribute.  Basically want to shed all particulars associated with random seed.\n",
    "        -generally try to shed any particulars in model that come from randomness (e.g. random initial conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
